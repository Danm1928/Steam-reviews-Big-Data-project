{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7cyQLIVHdFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87251b2c-358d-4794-f23f-4c71cc3df218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONHASHSEED=3\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#Install pyspark\n",
        "\n",
        "%env PYTHONHASHSEED 3\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!pip install -q pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup the pyspark session\n",
        "import pyspark\n",
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import *\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName('SparkExample').config(\n",
        "    \"spark.executor.memory\", \"1g\").config(\"spark.ui.port\", \"4050\"\n",
        "        ).getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "k4SU78NdHuy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "ZayTS3DRHywt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ijson"
      ],
      "metadata": {
        "id": "s4rM4UdLPFPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85063fdf-30d2-4391-85a4-3b6587bcc2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ijson\n",
            "  Downloading ijson-3.2.0.post0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.3/113.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ijson\n",
            "Successfully installed ijson-3.2.0.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import gzip\n",
        "\n",
        "#use the wget function to retrieve the data as the download link gives a\n",
        "#gz file, not a json\n",
        "!wget -O steam.gz https://datarepo.eng.ucsd.edu/mcauley_group/data/steam/australian_user_reviews.json.gz\n",
        "\n",
        "#load the data into an rdd\n",
        "steam_rdd = sc.textFile('steam.gz')\n",
        "\n",
        "#Extract whether or not a game is recommended and the review content\n",
        "steam_rdd = steam_rdd.flatMap(lambda x: [(review['recommend'], review['review']) for review in eval(x)['reviews']])\n",
        "\n",
        "#Test to see it has worked\n",
        "print(steam_rdd.take(5))\n",
        "\n",
        "#Split this RDD into two RDD's depending on whether or not a game is\n",
        "#recommended\n",
        "steam_rdd_true = steam_rdd.filter(lambda x: x[0] == True)\n",
        "steam_rdd_false = steam_rdd.filter(lambda x: x[0] == False)\n",
        "\n",
        "#Check that this has worked:\n",
        "print(steam_rdd_false.take(5))\n",
        "\n",
        "#See the length of each RDD:\n",
        "print(steam_rdd_true.count())\n",
        "print(steam_rdd_false.count())\n",
        "\n",
        "#Since we no longer need whether or not a game is recommended, we can get rid\n",
        "#of this value\n",
        "steam_rdd_true = steam_rdd_true.map(lambda x: x[1])\n",
        "steam_rdd_false = steam_rdd_false.map(lambda x: x[1])\n",
        "\n",
        "#Check this has also worked:\n",
        "print(steam_rdd_true.take(10))\n",
        "\n",
        "#Now we can move on to applying the tfidf algorithm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLZol8sMPG5h",
        "outputId": "fc55dbae-6d6a-4f47-8c95-6353675b409f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-02 08:03:52--  https://datarepo.eng.ucsd.edu/mcauley_group/data/steam/australian_user_reviews.json.gz\n",
            "Resolving datarepo.eng.ucsd.edu (datarepo.eng.ucsd.edu)... 132.239.8.30\n",
            "Connecting to datarepo.eng.ucsd.edu (datarepo.eng.ucsd.edu)|132.239.8.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6940139 (6.6M) [application/x-gzip]\n",
            "Saving to: ‘steam.gz’\n",
            "\n",
            "steam.gz            100%[===================>]   6.62M  15.1MB/s    in 0.4s    \n",
            "\n",
            "2023-06-02 08:03:53 (15.1 MB/s) - ‘steam.gz’ saved [6940139/6940139]\n",
            "\n",
            "[(True, 'Simple yet with great replayability. In my opinion does \"zombie\" hordes and team work better than left 4 dead plus has a global leveling system. Alot of down to earth \"zombie\" splattering fun for the whole family. Amazed this sort of FPS is so rare.'), (True, \"It's unique and worth a playthrough.\"), (True, 'Great atmosphere. The gunplay can be a bit chunky at times but at the end of the day this game is definitely worth it and I hope they do a sequel...so buy the game so I get a sequel!'), (True, 'I know what you think when you see this title \"Barbie Dreamhouse Party\" but do not be intimidated by it\\'s title, this is easily one of my GOTYs. You don\\'t get any of that cliche game mechanics that all the latest games have, this is simply good core gameplay. Yes, you can\\'t 360 noscope your friends, but what you can do is show them up with your bad ♥♥♥ dance moves and put them to shame as you show them what true fashion and color combinations are.I know this game says for kids but, this is easily for any age range and any age will have a blast playing this.8/8'), (True, \"For a simple (it's actually not all that simple but it can be!) truck driving Simulator, it is quite a fun and relaxing game. Playing on simple (or easy?) its just the basic WASD keys for driving but (if you want) the game can be much harder and realistic with having to manually change gears, much harder turning, etc. And reversing in this game is a ♥♥♥♥♥, as I imagine it would be with an actual truck. Luckily, you don't have to reverse park it but you get extra points if you do cause it is bloody hard. But this is suprisingly a nice truck driving game and I had a bit of fun with it.\")]\n",
            "[(False, \"This Game Doesn't Work\"), (False, '♥♥♥♥♥ charged me 80 now its 15 dollars, got boring after about 5 hours.'), (False, 'w,'), (False, 'เกมเเดกเงินดีๆนี้เอง'), (False, 'Emily is a thot')]\n",
            "52473\n",
            "6832\n",
            "['Simple yet with great replayability. In my opinion does \"zombie\" hordes and team work better than left 4 dead plus has a global leveling system. Alot of down to earth \"zombie\" splattering fun for the whole family. Amazed this sort of FPS is so rare.', \"It's unique and worth a playthrough.\", 'Great atmosphere. The gunplay can be a bit chunky at times but at the end of the day this game is definitely worth it and I hope they do a sequel...so buy the game so I get a sequel!', 'I know what you think when you see this title \"Barbie Dreamhouse Party\" but do not be intimidated by it\\'s title, this is easily one of my GOTYs. You don\\'t get any of that cliche game mechanics that all the latest games have, this is simply good core gameplay. Yes, you can\\'t 360 noscope your friends, but what you can do is show them up with your bad ♥♥♥ dance moves and put them to shame as you show them what true fashion and color combinations are.I know this game says for kids but, this is easily for any age range and any age will have a blast playing this.8/8', \"For a simple (it's actually not all that simple but it can be!) truck driving Simulator, it is quite a fun and relaxing game. Playing on simple (or easy?) its just the basic WASD keys for driving but (if you want) the game can be much harder and realistic with having to manually change gears, much harder turning, etc. And reversing in this game is a ♥♥♥♥♥, as I imagine it would be with an actual truck. Luckily, you don't have to reverse park it but you get extra points if you do cause it is bloody hard. But this is suprisingly a nice truck driving game and I had a bit of fun with it.\", 'Very fun little game to play when your bored or as a time passer. Very gud. Do Recommend. pls buy', \"A suitably punishing roguelike platformer.  Winning feels good.  Progressive unlocks mean a good slog ending in failure doesn't feel like a waste.\", '\"Run for fun? What the hell kind of fun is that?\"', 'Elegant integration of gameplay, story, world development and aesthetic.', 'Random drops and random quests, with stat points.  Animation style reminiscent of the era before the Voodoo card.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import time\n",
        "STOP_WORDS = set(stopwords.words('english'))\n",
        "\n",
        "#Use these functions to remove non letters:\n",
        "def remove_nonletters(word):\n",
        "  return re.sub(r'[^a-zA-Z]', '', word)\n",
        "\n",
        "def split_remove_nonletters(line):\n",
        "  result = []\n",
        "  for word in line.split(\" \"):\n",
        "    removed_token = remove_nonletters(word.lower())\n",
        "    if removed_token != '':\n",
        "      result.append((removed_token, 1))\n",
        "  return result\n",
        "\n",
        "#Wrap the process of counting words into a wordcount function:\n",
        "def wc(review):\n",
        "  result = {}\n",
        "  for words in review.split(\" \"):\n",
        "    removed_token = remove_nonletters(words.lower())\n",
        "    if removed_token != '' and removed_token not in STOP_WORDS:\n",
        "      if removed_token not in result:\n",
        "        result[removed_token] = 0\n",
        "      result[removed_token] += 1\n",
        "  return result\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "counts_true = steam_rdd_true.map(lambda x: wc(x))\n",
        "counts_false = steam_rdd_false.map(lambda x: wc(x))\n",
        "\n",
        "#Check this has worked okay\n",
        "print(counts_true.take(1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG8_ExHYVKOC",
        "outputId": "6bff06bb-52ea-4cc2-b512-7e3b4b8ec398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'simple': 1, 'yet': 1, 'great': 1, 'replayability': 1, 'opinion': 1, 'zombie': 2, 'hordes': 1, 'team': 1, 'work': 1, 'better': 1, 'left': 1, 'dead': 1, 'plus': 1, 'global': 1, 'leveling': 1, 'system': 1, 'alot': 1, 'earth': 1, 'splattering': 1, 'fun': 1, 'whole': 1, 'family': 1, 'amazed': 1, 'sort': 1, 'fps': 1, 'rare': 1}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#term frequency function to calculate the frequency of a given word in respect\n",
        "#to the document it belongs to\n",
        "#Will also need to turn the RDD of dictionaries into an RDD of tuples so we\n",
        "#can work with it\n",
        "\n",
        "def tf(doc_counts):\n",
        "  rdd_tuples = doc_counts.map(lambda x: list(x.items()))\n",
        "  return rdd_tuples.map(lambda x: [(k, (v / max([y[1] for y in x]))) for k, v in x])\n",
        "true_tf = tf(counts_true)\n",
        "false_tf = tf(counts_false)\n",
        "print(true_tf.take(2))\n",
        "print(false_tf.take(2))"
      ],
      "metadata": {
        "id": "XAlOCG6qd_qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13556919-20c1-474c-f22c-1a163d7f089b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('simple', 0.5), ('yet', 0.5), ('great', 0.5), ('replayability', 0.5), ('opinion', 0.5), ('zombie', 1.0), ('hordes', 0.5), ('team', 0.5), ('work', 0.5), ('better', 0.5), ('left', 0.5), ('dead', 0.5), ('plus', 0.5), ('global', 0.5), ('leveling', 0.5), ('system', 0.5), ('alot', 0.5), ('earth', 0.5), ('splattering', 0.5), ('fun', 0.5), ('whole', 0.5), ('family', 0.5), ('amazed', 0.5), ('sort', 0.5), ('fps', 0.5), ('rare', 0.5)], [('unique', 1.0), ('worth', 1.0), ('playthrough', 1.0)]]\n",
            "[[('game', 1.0), ('doesnt', 1.0), ('work', 1.0)], [('charged', 1.0), ('dollars', 1.0), ('got', 1.0), ('boring', 1.0), ('hours', 1.0)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate inverse document frequency\n",
        "\n",
        "import math\n",
        "def idf(count_rdds):\n",
        "  rdd_tuples = count_rdds.map(lambda x: list(x.items()))\n",
        "  n = rdd_tuples.count()\n",
        "  combined = rdd_tuples.flatMap(lambda x: x)\n",
        "  combined_tuple = combined.map(lambda x: (x[0], 1))\n",
        "  combined_reduced = combined_tuple.reduceByKey(lambda x, y: x+y)\n",
        "  final = combined_reduced.map(lambda x: (x[0], math.log(n/x[1], 2)))\n",
        "  return final\n",
        "\n",
        "true_idf = idf(counts_true)\n",
        "print(true_idf.take(30))\n",
        "false_idf = idf(counts_false)\n",
        "print(false_idf.take(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXCCfOk4D6_S",
        "outputId": "a1074c52-1ac3-4c22-9d4c-ab66537f28a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('simple', 6.175461916028362), ('yet', 5.9564801228545665), ('great', 2.956266722212081), ('replayability', 8.32173564940603), ('opinion', 6.937820667622965), ('zombie', 6.450468963528231), ('hordes', 10.094325153302956), ('team', 5.871932731966508), ('work', 5.840083865927169), ('better', 4.582572499535576), ('left', 6.921064439297387), ('dead', 6.787503950805802), ('plus', 7.484530799601865), ('global', 8.784469890716169), ('leveling', 9.1557256979671), ('system', 5.944578033798274), ('alot', 6.101858825988365), ('earth', 9.124698802346476), ('splattering', 14.094325153302956), ('fun', 2.7669596413370168), ('whole', 6.532082729081884), ('family', 8.499378564009179), ('amazed', 10.35735955913675), ('sort', 8.028235962845184), ('fps', 5.276275630449116), ('rare', 8.591824812773774), ('unique', 6.37550690584701), ('worth', 4.570763197245944), ('playthrough', 8.602472056973282), ('atmosphere', 7.772397058415594)]\n",
            "[('game', 0.9183123277820102), ('doesnt', 4.354387967146438), ('work', 4.411662772498188), ('charged', 10.416164164733129), ('dollars', 6.629567802842322), ('got', 3.963305200019317), ('boring', 4.499687520295412), ('hours', 4.320239744734593), ('w', 9.0376525414794), ('emily', 10.153129758899334), ('thot', 12.73809225962049), ('spent', 5.892602208676115), ('days', 6.629567802842322), ('making', 5.389364105389413), ('base', 6.693698140262037), ('man', 6.956732546095831), ('teleported', 9.930737337562887), ('spawned', 8.34577483684173), ('steel', 10.738092259620492), ('armour', 8.416164164733129)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tfidfi(tfi, idf):\n",
        "  tfi = tfi.flatMap(lambda x: x)\n",
        "  joined = tfi.join(idf)\n",
        "  multiply = joined.map(lambda x: (x[0], x[1][0]*x[1][1])).reduceByKey(lambda x, y: x + y)\n",
        "  #unioned = sc.union(to_union)\n",
        "  #reduced = unioned.reduceByKey(lambda x, y: x*y)\n",
        " # reduced = reduced.repartition(1)\n",
        "  return multiply\n",
        "\n",
        "#now we have the most important words in positive and negative reviews:\n",
        "true_tfidfi = tfidfi(true_tf, true_idf).takeOrdered(100, key = lambda x: (-x[1], x[0]))\n",
        "print(true_tfidfi)\n",
        "false_tfidfi = tfidfi(false_tf, false_idf).takeOrdered(100, key = lambda x: (-x[1], x[0]))\n",
        "print(false_tfidfi)\n",
        "\n",
        "time_end = time.time()\n",
        "print(f\"elapsed time is {time_end-time_start}\")\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "#Now lets actually compute the answer to my research question by removing\n",
        "#important words that are common between positive and negative reviews,\n",
        "set_true = set(item[0] for item in true_tfidfi)\n",
        "set_false = set(item[0] for item in false_tfidfi)\n",
        "\n",
        "common_words = set_true.intersection(set_false)\n",
        "\n",
        "set_true = set(item for item in true_tfidfi if item[0] not in common_words)\n",
        "set_false = set(item for item in false_tfidfi if item[0] not in common_words)\n",
        "\n",
        "list_true = list(set_true)\n",
        "list_false = list(set_false)\n",
        "\n",
        "print(list_true)\n",
        "print(list_false)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWRObcObNCdk",
        "outputId": "276a82f9-7d5d-47bd-da6e-f8807f7efac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('game', 23166.553527125972), ('good', 15153.297396722517), ('fun', 15061.014893592095), ('great', 13711.760770153725), ('play', 12502.319905297769), ('best', 12151.80382828794), ('like', 11634.699935638404), ('get', 10899.939983324433), ('would', 9696.135841314997), ('one', 9594.76162135919), ('really', 9263.171518724024), ('games', 9084.526818706998), ('awesome', 8907.105793903622), ('love', 8408.11164383609), ('ever', 8406.665598538206), ('amazing', 8195.228602727859), ('played', 7816.794808270157), ('time', 7091.218350533951), ('buy', 6651.049610927495), ('much', 6639.616563529974), ('dont', 6573.571394624949), ('playing', 6135.547921580345), ('recommend', 6027.00721777465), ('still', 5930.160735942393), ('friends', 5838.166395579024), ('worth', 5613.104701924476), ('better', 5587.0721076446935), ('people', 5571.311828134626), ('story', 5506.74398786709), ('hours', 5426.78556271918), ('even', 5258.730170297355), ('free', 5159.35837050103), ('jogo', 5148.413121250958), ('well', 5101.30530676781), ('got', 5053.898554782167), ('de', 5022.235135107867), ('gameplay', 4983.527173076203), ('pretty', 4922.260920204124), ('make', 4903.838259125871), ('first', 4836.436975693524), ('want', 4713.092784367367), ('ive', 4670.640964174287), ('new', 4491.859649415041), ('nice', 4431.47014800007), ('fps', 4413.783783955083), ('graphics', 4386.208407666027), ('many', 4372.510003514956), ('im', 4369.5231057292185), ('cant', 4324.562153604778), ('life', 4279.43879326272), ('go', 4257.097253244291), ('also', 4254.802332592695), ('que', 4121.2646196193555), ('made', 3972.0225732326044), ('muito', 3951.3252793955057), ('e', 3931.4757728189543), ('say', 3863.4795468347493), ('think', 3800.6060323286083), ('bit', 3794.785066100228), ('need', 3773.369375811621), ('cool', 3665.28562056338), ('though', 3622.6753329953044), ('little', 3565.998658155837), ('every', 3536.2483615585897), ('multiplayer', 3506.41289167382), ('way', 3489.542042433359), ('must', 3480.1620883295045), ('lot', 3436.1937347912703), ('could', 3408.1729365420183), ('hard', 3389.9220925764953), ('never', 3387.101987978006), ('know', 3321.041465008899), ('money', 3307.1815512470675), ('bad', 3299.9229793690283), ('world', 3278.5315412681484), ('things', 3277.5370473079156), ('u', 3231.8162552476692), ('steam', 3208.4302660542794), ('highly', 3188.613582447581), ('give', 3185.6981124893023), ('makes', 3173.5208405996277), ('around', 3157.1912524632744), ('see', 3148.7750820786846), ('bom', 3122.868712084458), ('simulator', 3096.383439895742), ('kill', 3094.7755023698523), ('back', 3072.4293653488867), ('far', 3004.4031692766994), ('ing', 2946.5294919448725), ('feel', 2937.200595226924), ('find', 2835.4559039310607), ('different', 2810.251876653955), ('anyone', 2795.8456332692685), ('youre', 2780.138709352074), ('try', 2749.3308722842826), ('shooter', 2715.8404341554233), ('experience', 2704.984949823009), ('team', 2703.901570483762), ('addictive', 2697.7178589955197), ('thing', 2682.134737909354)]\n",
            "[('game', 2865.373943843742), ('play', 1640.8152334324516), ('dont', 1580.4517656945384), ('like', 1529.637220695378), ('get', 1513.5931918000529), ('good', 1339.9842473722927), ('even', 1326.434980797124), ('cant', 1216.146466040707), ('buy', 1214.8645424472277), ('would', 1134.6592767846714), ('money', 1110.9509775525541), ('really', 1081.0374659845631), ('bad', 1044.9640814631748), ('one', 1041.9735890580114), ('fun', 1041.809507429487), ('time', 979.8674179231349), ('ing', 957.2199140159347), ('games', 951.0047917601208), ('got', 874.2281670550291), ('much', 871.1274307529719), ('want', 864.0564899347107), ('ever', 838.2434094436475), ('boring', 816.6145254180373), ('played', 803.7220084880071), ('better', 794.430643306196), ('still', 792.9623662331115), ('playing', 779.5993223474994), ('work', 779.5941093888059), ('great', 770.8226894651178), ('worth', 752.9793047045392), ('people', 750.4047639003088), ('go', 729.4604404850612), ('im', 717.6506656389166), ('doesnt', 715.3371565752152), ('waste', 709.8454480537348), ('make', 702.1657777842835), ('pay', 684.4192827346462), ('gameplay', 670.9689945708981), ('de', 661.0618475013638), ('worst', 650.213941133358), ('back', 648.7630191999561), ('recommend', 648.6263746345334), ('first', 643.3726967844374), ('hours', 639.7349513981493), ('could', 635.7406823414237), ('terrible', 629.8858711220144), ('dlc', 628.663576817849), ('fix', 627.3168473840307), ('new', 620.6081891574057), ('free', 616.5734314887061), ('made', 607.2300277811132), ('well', 604.1161654477422), ('way', 603.1616911259449), ('que', 599.8052852602157), ('pretty', 594.5114389886064), ('steam', 580.4006597154537), ('never', 578.4546059643608), ('ive', 573.3317427785096), ('many', 569.3557842692617), ('servers', 564.5422653395541), ('pc', 560.7392420245268), ('thing', 556.9248974464316), ('nothing', 556.4155276877401), ('know', 556.0663138362806), ('didnt', 552.5954858767353), ('need', 551.3703743191338), ('sucks', 547.7536397781482), ('graphics', 540.4986033344612), ('every', 540.3286256530049), ('crashes', 525.8997123767512), ('server', 521.28539144969), ('bought', 521.2705586269277), ('find', 516.8464480660987), ('jogo', 512.4042066374543), ('hard', 507.99811514529296), ('system', 501.8335165147976), ('also', 500.96008384607495), ('u', 495.99768256096513), ('run', 494.9487478492029), ('see', 494.92888054870116), ('minutes', 494.2603044356289), ('horrible', 493.11741568021324), ('crap', 492.3287911101283), ('give', 484.19807191360246), ('players', 480.06303667542664), ('fps', 477.97542073444924), ('say', 477.89290436041955), ('story', 474.6492954115437), ('start', 467.33526498419496), ('e', 466.98358686020447), ('something', 463.473985175569), ('think', 455.1585126342312), ('full', 453.3143539207662), ('win', 450.81589605519287), ('update', 438.98769691652564), ('refund', 436.5252839626037), ('going', 434.4985444052798), ('thats', 433.38428283524007), ('actually', 433.053641160042), ('wont', 432.6751599106353)]\n",
            "elapsed time is 63.53863549232483\n",
            "\n",
            "[('kill', 3094.7755023698523), ('makes', 3173.5208405996277), ('different', 2810.251876653955), ('bit', 3794.785066100228), ('try', 2749.3308722842826), ('anyone', 2795.8456332692685), ('experience', 2704.984949823009), ('love', 8408.11164383609), ('cool', 3665.28562056338), ('awesome', 8907.105793903622), ('bom', 3122.868712084458), ('friends', 5838.166395579024), ('must', 3480.1620883295045), ('best', 12151.80382828794), ('lot', 3436.1937347912703), ('feel', 2937.200595226924), ('team', 2703.901570483762), ('nice', 4431.47014800007), ('world', 3278.5315412681484), ('youre', 2780.138709352074), ('far', 3004.4031692766994), ('life', 4279.43879326272), ('muito', 3951.3252793955057), ('around', 3157.1912524632744), ('little', 3565.998658155837), ('amazing', 8195.228602727859), ('addictive', 2697.7178589955197), ('though', 3622.6753329953044), ('multiplayer', 3506.41289167382), ('things', 3277.5370473079156), ('shooter', 2715.8404341554233), ('highly', 3188.613582447581), ('simulator', 3096.383439895742)]\n",
            "[('system', 501.8335165147976), ('update', 438.98769691652564), ('worst', 650.213941133358), ('pc', 560.7392420245268), ('terrible', 629.8858711220144), ('work', 779.5941093888059), ('fix', 627.3168473840307), ('run', 494.9487478492029), ('something', 463.473985175569), ('dlc', 628.663576817849), ('going', 434.4985444052798), ('bought', 521.2705586269277), ('boring', 816.6145254180373), ('nothing', 556.4155276877401), ('thats', 433.38428283524007), ('horrible', 493.11741568021324), ('server', 521.28539144969), ('waste', 709.8454480537348), ('wont', 432.6751599106353), ('pay', 684.4192827346462), ('didnt', 552.5954858767353), ('full', 453.3143539207662), ('minutes', 494.2603044356289), ('doesnt', 715.3371565752152), ('servers', 564.5422653395541), ('sucks', 547.7536397781482), ('refund', 436.5252839626037), ('crap', 492.3287911101283), ('start', 467.33526498419496), ('crashes', 525.8997123767512), ('win', 450.81589605519287), ('actually', 433.053641160042), ('players', 480.06303667542664)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now do market basket analysis on the dataset, finding frequent pairs can also\n",
        "#be helpful in finding common/important words, and is interesting for those\n",
        "#who may want to look into steam reviews\n",
        "\n",
        "#make sure this function excludes nonletters and stop words\n",
        "def split_remove_spaces(line):\n",
        "  result = []\n",
        "  for word in line.split(\" \"):\n",
        "    removed_token = remove_nonletters(word.lower())\n",
        "    if removed_token != '' and removed_token not in STOP_WORDS:\n",
        "      result.append(removed_token)\n",
        "  return result\n",
        "\n",
        "#helper function to find all pairs of words in each review\n",
        "def helper(string):\n",
        "  split = split_remove_spaces(string)\n",
        "  pairs = []\n",
        "  for i in range(len(split)):\n",
        "    for j in range(i+1, len(split)):\n",
        "      pairs.append(tuple(sorted((split[i], split[j]))))\n",
        "  return pairs\n",
        "\n",
        "#step 1 of the apriori function which returns counts of individual words\n",
        "def a_priori_step1(text_file_rdd):\n",
        "  mapped = text_file_rdd.map(lambda x: split_remove_spaces(x)).flatMap(lambda x: x)\n",
        "  mapped = mapped.map(lambda x: (x, 1))\n",
        "  reduced = mapped.reduceByKey(lambda x, y: x + y)\n",
        "  return reduced\n",
        "\n",
        "steam_apriori_true = a_priori_step1(steam_rdd_true).takeOrdered(20, lambda kv: -kv[1])\n",
        "print(steam_apriori_true)\n",
        "\n",
        "steam_apriori_false = a_priori_step1(steam_rdd_false).takeOrdered(20, lambda kv: -kv[1])\n",
        "print(steam_apriori_false)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyRYSDjp19FS",
        "outputId": "2e74ff20-53e0-4c32-829e-4d560fbabbf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('game', 50174), ('good', 9262), ('fun', 9244), ('like', 8884), ('play', 8558), ('great', 8319), ('get', 7847), ('one', 6373), ('really', 5795), ('games', 5684), ('best', 5588), ('would', 5582), ('time', 4388), ('played', 3895), ('dont', 3882), ('much', 3792), ('amazing', 3648), ('love', 3647), ('awesome', 3418), ('playing', 3357)]\n",
            "[('game', 8517), ('like', 1661), ('get', 1627), ('play', 1502), ('bad', 1410), ('dont', 1359), ('even', 1166), ('good', 1094), ('would', 950), ('one', 934), ('time', 889), ('really', 884), ('buy', 802), ('fun', 769), ('games', 759), ('cant', 739), ('want', 687), ('much', 667), ('money', 650), ('new', 627)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#perform the second step of the apriori algorithm\n",
        "\n",
        "def a_priori(text_file_rdd, support=100):\n",
        "  step1 = a_priori_step1(text_file_rdd)\n",
        "  filtered = step1.filter(lambda x: x[1] >= support)\n",
        "  to_broadcast = filtered.collectAsMap()\n",
        "  broadcasted = sc.broadcast(to_broadcast)\n",
        "\n",
        "  mapped = text_file_rdd.map(lambda x: helper(x)).map(lambda x: [pair for pair in x if all(word in broadcasted.value for word in pair)])\n",
        "  mapped = mapped.flatMap(lambda x: x)\n",
        "  mapped = mapped.map(lambda x: (x, 1))\n",
        "  reduced = mapped.reduceByKey(lambda x, y: x + y)\n",
        "  return reduced\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "steam_apriori_true_final = a_priori(steam_rdd_true).takeOrdered(20, lambda kv: -kv[1])\n",
        "print(steam_apriori_true_final)\n",
        "\n",
        "steam_apriori_false_final = a_priori(steam_rdd_false).takeOrdered(20, lambda kv: -kv[1])\n",
        "print(steam_apriori_false_final)\n",
        "\n",
        "time_end = time.time()\n",
        "print(f\"elapsed time is {time_end-time_start}\")\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "#Compute the answer to the research question, find the actual difference\n",
        "\n",
        "set_true = set(item[0] for item in steam_apriori_true_final)\n",
        "set_false = set(item[0] for item in steam_apriori_false_final)\n",
        "\n",
        "common_words = set_true.intersection(set_false)\n",
        "\n",
        "set_true = set(item for item in steam_apriori_true_final if item[0] not in common_words)\n",
        "set_false = set(item for item in steam_apriori_false_final if item[0] not in common_words)\n",
        "\n",
        "list_true = list(set_true)\n",
        "list_false = list(set_false)\n",
        "\n",
        "print(list_true)\n",
        "print(list_false)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR_3Q_-r3P-E",
        "outputId": "39dc16e3-9be3-4c61-d8ab-8078b2141b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(('hat', 'hat'), 1999043), (('nyan', 'nyan'), 1279200), (('hats', 'hats'), 181154), (('hot', 'super'), 152108), (('shit', 'shit'), 139129), (('pew', 'pew'), 114572), (('hit', 'shit'), 91344), (('super', 'super'), 75987), (('hot', 'hot'), 75870), (('pew', 'pewpew'), 75682), (('game', 'game'), 65636), (('john', 'madden'), 46666), (('warriordragon', 'warriordragon'), 35245), (('exile', 'path'), 34244), (('buy', 'itbuy'), 31327), (('shower', 'took'), 29929), (('dadi', 'took'), 29756), (('dadi', 'shower'), 29756), (('rep', 'rep'), 29647), (('game', 'like'), 27699)]\n",
            "[(('bad', 'bad'), 332683), (('dlc', 'new'), 28030), (('new', 'update'), 28001), (('adds', 'dlc'), 27923), (('dlc', 'update'), 27917), (('adds', 'new'), 27901), (('dlc', 'overpriced'), 27897), (('new', 'overpriced'), 27894), (('overpriced', 'update'), 27893), (('adds', 'update'), 27889), (('adds', 'overpriced'), 27889), (('game', 'game'), 16224), (('dlc', 'dlc'), 14179), (('new', 'new'), 14043), (('update', 'update'), 13910), (('adds', 'adds'), 13862), (('overpriced', 'overpriced'), 13861), (('hats', 'hats'), 9047), (('game', 'like'), 7011), (('game', 'get'), 6628)]\n",
            "elapsed time is 177.8636622428894\n",
            "\n",
            "[(('exile', 'path'), 34244), (('shower', 'took'), 29929), (('shit', 'shit'), 139129), (('hot', 'super'), 152108), (('super', 'super'), 75987), (('hot', 'hot'), 75870), (('hat', 'hat'), 1999043), (('hit', 'shit'), 91344), (('warriordragon', 'warriordragon'), 35245), (('dadi', 'shower'), 29756), (('buy', 'itbuy'), 31327), (('pew', 'pewpew'), 75682), (('john', 'madden'), 46666), (('dadi', 'took'), 29756), (('rep', 'rep'), 29647), (('nyan', 'nyan'), 1279200), (('pew', 'pew'), 114572)]\n",
            "[(('dlc', 'update'), 27917), (('game', 'get'), 6628), (('new', 'overpriced'), 27894), (('new', 'update'), 28001), (('dlc', 'overpriced'), 27897), (('new', 'new'), 14043), (('update', 'update'), 13910), (('adds', 'adds'), 13862), (('adds', 'update'), 27889), (('dlc', 'new'), 28030), (('adds', 'overpriced'), 27889), (('overpriced', 'update'), 27893), (('overpriced', 'overpriced'), 13861), (('adds', 'new'), 27901), (('adds', 'dlc'), 27923), (('dlc', 'dlc'), 14179), (('bad', 'bad'), 332683)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We have seen how the code performs on the full datasets now, lets test it at\n",
        "#a quarter, half and three quarters of the datasets:\n",
        "\n",
        "steam_rdd_true_quarter = steam_rdd_true.take(13118)\n",
        "steam_rdd_true_quarter = sc.parallelize(steam_rdd_true_quarter)\n",
        "steam_rdd_true_half = steam_rdd_true.take(26236)\n",
        "steam_rdd_true_half = sc.parallelize(steam_rdd_true_half)\n",
        "steam_rdd_true_threequarters = steam_rdd_true.take(39354)\n",
        "steam_rdd_true_threequarters = sc.parallelize(steam_rdd_true_threequarters)\n",
        "\n",
        "steam_rdd_false_quarter = steam_rdd_false.take(1708)\n",
        "steam_rdd_false_quarter = sc.parallelize(steam_rdd_false_quarter)\n",
        "steam_rdd_false_half = steam_rdd_false.take(3416)\n",
        "steam_rdd_false_half = sc.parallelize(steam_rdd_false_half)\n",
        "steam_rdd_false_threequarters = steam_rdd_false.take(5124)\n",
        "steam_rdd_false_threequarters = sc.parallelize(steam_rdd_false_threequarters)\n",
        "\n",
        "#time_start = time.time()\n",
        "\n",
        "#time_end = time.time()\n",
        "#print(f\"elapsed time is {time_end-time_start}\")\n",
        "\n",
        "print(\"Quarter:\")\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "counts_true_quarter = steam_rdd_true_quarter.map(lambda x: wc(x))\n",
        "counts_false_quarter = steam_rdd_false_quarter.map(lambda x: wc(x))\n",
        "\n",
        "true_tf_quarter = tf(counts_true_quarter)\n",
        "false_tf_quarter = tf(counts_false_quarter)\n",
        "\n",
        "true_idf_quarter = idf(counts_true_quarter)\n",
        "false_idf_quarter = idf(counts_false_quarter)\n",
        "\n",
        "true_tfidfi_quarter = tfidfi(true_tf_quarter, true_idf_quarter).takeOrdered(100, key = lambda x: (-x[1], x[0]))\n",
        "false_tfidfi_quarter = tfidfi(false_tf_quarter, false_idf_quarter).takeOrdered(100, key = lambda x: (-x[1], x[0]))\n",
        "\n",
        "time_end = time.time()\n",
        "print(f\"elapsed time is (tfidf) {time_end-time_start}\")\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "steam_apriori_true_final_quarter = a_priori(steam_rdd_true_quarter).takeOrdered(20, lambda kv: -kv[1])\n",
        "steam_apriori_false_final_quarter = a_priori(steam_rdd_false_quarter).takeOrdered(20, lambda kv: -kv[1])\n",
        "\n",
        "time_end = time.time()\n",
        "print(f\"elapsed time is (market basket) {time_end-time_start}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThADwHXlYG4J",
        "outputId": "fc4da3ec-4e62-4e46-a6b3-ff2ae2dfefe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quarter:\n",
            "elapsed time is (tfidf) 14.157914638519287\n",
            "elapsed time is (market basket) 36.832727909088135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Half:\")\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "counts_true_half = steam_rdd_true_half.map(lambda x: wc(x))\n",
        "counts_false_half = steam_rdd_false_half.map(lambda x: wc(x))\n",
        "\n",
        "true_tf_half = tf(counts_true_half)\n",
        "false_tf_half = tf(counts_false_half)\n",
        "\n",
        "true_idf_half = idf(counts_true_half)\n",
        "false_idf_half = idf(counts_false_half)\n",
        "\n",
        "true_tfidfi_half = tfidfi(true_tf_half, true_idf_half).takeOrdered(100, key = lambda x: (-x[1], x[0]))\n",
        "false_tfidfi_half = tfidfi(false_tf_half, false_idf_half).takeOrdered(100, key = lambda x: (-x[1], x[0]))\n",
        "\n",
        "time_end = time.time()\n",
        "print(f\"elapsed time is (tfidf) {time_end-time_start}\")\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "steam_apriori_true_final_half = a_priori(steam_rdd_true_half).takeOrdered(20, lambda kv: -kv[1])\n",
        "steam_apriori_false_final_half = a_priori(steam_rdd_false_half).takeOrdered(20, lambda kv: -kv[1])\n",
        "\n",
        "time_end = time.time()\n",
        "print(f\"elapsed time is (market basket) {time_end-time_start}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0YL_VxbeZMM",
        "outputId": "ae57a0ba-d02c-49de-cdcd-9133f7ba806f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Half:\n",
            "elapsed time is (tfidf) 19.201499938964844\n",
            "elapsed time is (market basket) 71.8371307849884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Three quarters:\")\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "counts_true_threequarters = steam_rdd_true_threequarters.map(lambda x: wc(x))\n",
        "counts_false_threequarters = steam_rdd_false_threequarters.map(lambda x: wc(x))\n",
        "\n",
        "true_tf_threequarters = tf(counts_true_threequarters)\n",
        "false_tf_threequarters = tf(counts_false_threequarters)\n",
        "\n",
        "true_idf_threequarters = idf(counts_true_threequarters)\n",
        "false_idf_threequarters = idf(counts_false_threequarters)\n",
        "\n",
        "true_tfidfi_threequarters = tfidfi(true_tf_threequarters, true_idf_threequarters).takeOrdered(100, key = lambda x: (-x[1], x[0]))\n",
        "false_tfidfi_threequarters = tfidfi(false_tf_threequarters, false_idf_threequarters).takeOrdered(100, key = lambda x: (-x[1], x[0]))\n",
        "\n",
        "time_end = time.time()\n",
        "print(f\"elapsed time is (tfidf) {time_end-time_start}\")\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "steam_apriori_true_final_threequarters = a_priori(steam_rdd_true_threequarters).takeOrdered(20, lambda kv: -kv[1])\n",
        "steam_apriori_false_final_threequarters = a_priori(steam_rdd_false_threequarters).takeOrdered(20, lambda kv: -kv[1])\n",
        "\n",
        "time_end = time.time()\n",
        "print(f\"elapsed time is (market basket) {time_end-time_start}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4r1smiVfr9N",
        "outputId": "62df3b56-ff0b-4793-b645-7cb0a8042345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Three quarters:\n",
            "elapsed time is (tfidf) 26.43730592727661\n",
            "elapsed time is (market basket) 122.11415076255798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pyspark_project.py\n",
        "import pyspark\n",
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import *\n",
        "import json\n",
        "import gzip\n",
        "import re\n",
        "import sys\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import math\n",
        "import time\n",
        "\n",
        "if len(sys.argv) < 2:\n",
        "  raise Exception(\"Input URI required\")\n",
        "\n",
        "sc = pyspark.SparkContext()\n",
        "\n",
        "steam_rdd = sc.textFile(sys.argv[1])\n",
        "\n",
        "steam_rdd = steam_rdd.flatMap(lambda x: [(review['recommend'], review['review']) for review in eval(x)['reviews']])\n",
        "\n",
        "steam_rdd_true = steam_rdd.filter(lambda x: x[0] == True)\n",
        "steam_rdd_false = steam_rdd.filter(lambda x: x[0] == False)\n",
        "\n",
        "steam_rdd_true = steam_rdd_true.map(lambda x: x[1])\n",
        "steam_rdd_false = steam_rdd_false.map(lambda x: x[1])\n",
        "\n",
        "STOP_WORDS = set(stopwords.words('english'))\n",
        "\n",
        "def remove_nonletters(word):\n",
        "  return re.sub(r'[^a-zA-Z]', '', word)\n",
        "\n",
        "def split_remove_nonletters(line):\n",
        "  result = []\n",
        "  for word in line.split(\" \"):\n",
        "    removed_token = remove_nonletters(word.lower())\n",
        "    if removed_token != '':\n",
        "      result.append((removed_token, 1))\n",
        "  return result\n",
        "\n",
        "def wc(review):\n",
        "  result = {}\n",
        "  for words in review.split(\" \"):\n",
        "    removed_token = remove_nonletters(words.lower())\n",
        "    if removed_token != '' and removed_token not in STOP_WORDS:\n",
        "      if removed_token not in result:\n",
        "        result[removed_token] = 0\n",
        "      result[removed_token] += 1\n",
        "  return result\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "counts_true = steam_rdd_true.map(lambda x: wc(x))\n",
        "counts_false = steam_rdd_false.map(lambda x: wc(x))\n",
        "\n",
        "def tf(doc_counts):\n",
        "  rdd_tuples = doc_counts.map(lambda x: list(x.items()))\n",
        "  return rdd_tuples.map(lambda x: [(k, (v / max([y[1] for y in x]))) for k, v in x])\n",
        "true_tf = tf(counts_true)\n",
        "false_tf = tf(counts_false)\n",
        "\n",
        "def idf(count_rdds):\n",
        "  rdd_tuples = count_rdds.map(lambda x: list(x.items()))\n",
        "  n = rdd_tuples.count()\n",
        "  combined = rdd_tuples.flatMap(lambda x: x)\n",
        "  combined_tuple = combined.map(lambda x: (x[0], 1))\n",
        "  combined_reduced = combined_tuple.reduceByKey(lambda x, y: x+y)\n",
        "  final = combined_reduced.map(lambda x: (x[0], math.log(n/x[1], 2)))\n",
        "  return final\n",
        "\n",
        "true_idf = idf(counts_true)\n",
        "false_idf = idf(counts_false)\n",
        "\n",
        "def tfidfi(tfi, idf):\n",
        "  tfi = tfi.flatMap(lambda x: x)\n",
        "  joined = tfi.join(idf)\n",
        "  multiply = joined.map(lambda x: (x[0], x[1][0]*x[1][1])).reduceByKey(lambda x, y: x + y)\n",
        "  #unioned = sc.union(to_union)\n",
        "  #reduced = unioned.reduceByKey(lambda x, y: x*y)\n",
        " # reduced = reduced.repartition(1)\n",
        "  return multiply\n",
        "\n",
        "true_tfidfi = tfidfi(true_tf, true_idf).takeOrdered(100, key = lambda x: (-x[1], x[0]))\n",
        "false_tfidfi = tfidfi(false_tf, false_idf).takeOrdered(100, key = lambda x: (-x[1], x[0]))\n",
        "\n",
        "time_end = time.time()\n",
        "print(f\"elapsed time is (tfidf) {time_end-time_start}\")\n",
        "\n",
        "def split_remove_spaces(line):\n",
        "  result = []\n",
        "  for word in line.split(\" \"):\n",
        "    removed_token = remove_nonletters(word.lower())\n",
        "    if removed_token != '' and removed_token not in STOP_WORDS:\n",
        "      result.append(removed_token)\n",
        "  return result\n",
        "\n",
        "def helper(string):\n",
        "  split = split_remove_spaces(string)\n",
        "  pairs = []\n",
        "  for i in range(len(split)):\n",
        "    for j in range(i+1, len(split)):\n",
        "      pairs.append(tuple(sorted((split[i], split[j]))))\n",
        "  return pairs\n",
        "\n",
        "def a_priori_step1(text_file_rdd):\n",
        "  mapped = text_file_rdd.map(lambda x: split_remove_spaces(x)).flatMap(lambda x: x)\n",
        "  mapped = mapped.map(lambda x: (x, 1))\n",
        "  reduced = mapped.reduceByKey(lambda x, y: x + y)\n",
        "  return reduced\n",
        "\n",
        "steam_apriori_true = a_priori_step1(steam_rdd_true).takeOrdered(20, lambda kv: -kv[1])\n",
        "steam_apriori_false = a_priori_step1(steam_rdd_false).takeOrdered(20, lambda kv: -kv[1])\n",
        "\n",
        "def a_priori(text_file_rdd, support=100):\n",
        "  step1 = a_priori_step1(text_file_rdd)\n",
        "  filtered = step1.filter(lambda x: x[1] >= support)\n",
        "  to_broadcast = filtered.collectAsMap()\n",
        "  broadcasted = sc.broadcast(to_broadcast)\n",
        "\n",
        "  mapped = text_file_rdd.map(lambda x: helper(x)).map(lambda x: [pair for pair in x if all(word in broadcasted.value for word in pair)])\n",
        "  mapped = mapped.flatMap(lambda x: x)\n",
        "  mapped = mapped.map(lambda x: (x, 1))\n",
        "  reduced = mapped.reduceByKey(lambda x, y: x + y)\n",
        "  return reduced\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "steam_apriori_true_final = a_priori(steam_rdd_true).takeOrdered(20, lambda kv: -kv[1])\n",
        "print(steam_apriori_true_final)\n",
        "\n",
        "steam_apriori_false_final = a_priori(steam_rdd_false).takeOrdered(20, lambda kv: -kv[1])\n",
        "print(steam_apriori_false_final)\n",
        "\n",
        "time_end = time.time()\n",
        "print(f\"elapsed time is (market basket) {time_end-time_start}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_dUjacYB5gx",
        "outputId": "f82f55ad-43a9-44fb-ae50-19393faaad06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing pyspark_project.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USERNAME=\"dcollett\"\n",
        "%env REGION=australia-southeast1\n",
        "%env ZONE=australia-southeast1-a\n",
        "%env PROJECT=data301-2023-$USERNAME\n",
        "%env CLUSTER=data301-2023-$USERNAME-project-cluster\n",
        "%env BUCKET=data301-2023-$USERNAME-project-bucket"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HefRofSiALs5",
        "outputId": "7a7cb9db-1a51-490b-99ae-054e91e42287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: REGION=australia-southeast1\n",
            "env: ZONE=australia-southeast1-a\n",
            "env: PROJECT=data301-2023-dcollett\n",
            "env: CLUSTER=data301-2023-dcollett-project-cluster\n",
            "env: BUCKET=data301-2023-dcollett-project-bucket\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install google-cloud-dataproc[libcst]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vnj_1kcxBAUO",
        "outputId": "f3493f32-6027-47f7-a188-8c0a062ce76c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting google-cloud-dataproc[libcst]\n",
            "  Downloading google_cloud_dataproc-5.4.1-py2.py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.5/307.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: google-cloud-dataproc 5.4.1 does not provide the extra 'libcst'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-dataproc[libcst]) (2.11.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-dataproc[libcst]) (1.22.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-dataproc[libcst]) (3.20.3)\n",
            "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-dataproc[libcst])\n",
            "  Downloading grpc_google_iam_v1-0.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc[libcst]) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc[libcst]) (2.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc[libcst]) (2.27.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc[libcst]) (1.54.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc[libcst]) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc[libcst]) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc[libcst]) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc[libcst]) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc[libcst]) (4.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc[libcst]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc[libcst]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc[libcst]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc[libcst]) (3.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-dataproc[libcst]) (0.5.0)\n",
            "Installing collected packages: grpc-google-iam-v1, google-cloud-dataproc\n",
            "Successfully installed google-cloud-dataproc-5.4.1 grpc-google-iam-v1-0.12.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZR6NVo6BFZa",
        "outputId": "ca981f26-f173-47a1-b023-22018496ddc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=nnQ0DJL6GKWpEx4XmFA6MPYRKn7DzU&prompt=consent&access_type=offline&code_challenge=2h3GEJYMzWBZ0FZWZSwyvPGRcqIiy7a8s7dWlwEg1Zk&code_challenge_method=S256\n",
            "\n",
            "Enter authorization code: 4/0AbUR2VN-vQBJC0NQeNL-bW3UBYNIRLq0vSKkbh-RHDLjm7jciWZ3ywSx8rcVnBkezFCzwg\n",
            "\n",
            "You are now logged in as [khoretto@gmail.com].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project $PROJECT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGhg2aoMBQJp",
        "outputId": "7d8a0cd3-59bc-4c38-f95c-2cd6a3fa2810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud services enable dataproc.googleapis.com cloudresourcemanager.googleapis.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osHtBunpBUaT",
        "outputId": "43a03f8f-66f0-4bec-d4f9-f461913d7647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Operation \"operations/acat.p2-891767847038-5eb6f2fc-e560-4430-addf-7498c1e7a7e7\" finished successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil mb -c regional -l $REGION -p $PROJECT gs://$BUCKET"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LzZMU9-BYNs",
        "outputId": "27f1e2d1-7d88-4b3c-c082-47b7697411fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating gs://data301-2023-dcollett-project-bucket/...\n",
            "ServiceException: 409 A Cloud Storage bucket named 'data301-2023-dcollett-project-bucket' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud storage cp ./steam.gz gs://$BUCKET"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC9CjvbHBaz2",
        "outputId": "313ec86e-534b-4bcf-d9b0-628c640416b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://./steam.gz to gs://data301-2023-dcollett-project-bucket/steam.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud storage cp ./nltk.zip gs://$BUCKET"
      ],
      "metadata": {
        "id": "qgry24-1MzBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb512490-4da7-485c-9718-6b1e2f69496a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://./nltk.zip to gs://data301-2023-dcollett-project-bucket/nltk.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud dataproc clusters create $CLUSTER --region=$REGION --bucket=$BUCKET --zone=$ZONE \\\n",
        "--master-machine-type=n1-standard-2 --worker-machine-type=n1-standard-1 \\\n",
        "--image-version=1.5 --max-age=30m --num-masters=1 --num-workers=2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BPbkIuiEy-2",
        "outputId": "fe2aa9a5-72cf-48b6-8924-d81d167342b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting on operation [projects/data301-2023-dcollett/regions/australia-southeast1/operations/80f6c501-e0e2-310b-9e1f-e8ba74720365].\n",
            "\n",
            "\u001b[1;33mWARNING:\u001b[0m Consider using Auto Zone rather than selecting a zone manually. See https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone\n",
            "\u001b[1;33mWARNING:\u001b[0m Creating clusters using the n1-standard-1 machine type is not recommended. Consider using a machine type with higher memory.\n",
            "\u001b[1;33mWARNING:\u001b[0m Permissions are missing for the default service account '891767847038-compute@developer.gserviceaccount.com', missing permissions: [storage.objects.get, storage.objects.update] on the staging_bucket 'projects/_/buckets/data301-2023-dcollett-project-bucket'. This usually happens when a custom resource (ex: custom staging bucket) or a user-managed VM Service account has been provided and the default/user-managed service account hasn't been granted enough permissions on the resource. See https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/service-accounts#VM_service_account.\n",
            "\u001b[1;33mWARNING:\u001b[0m Permissions are missing for the default service account '891767847038-compute@developer.gserviceaccount.com', missing permissions: [storage.objects.get, storage.objects.update] on the temp_bucket 'projects/_/buckets/dataproc-temp-au-southeast1-891767847038-0dslfl3m'. This usually happens when a custom resource (ex: custom staging bucket) or a user-managed VM Service account has been provided and the default/user-managed service account hasn't been granted enough permissions on the resource. See https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/service-accounts#VM_service_account.\n",
            "Created [https://dataproc.googleapis.com/v1/projects/data301-2023-dcollett/regions/australia-southeast1/clusters/data301-2023-dcollett-project-cluster] Cluster placed in zone [australia-southeast1-a].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy0UhVKGLRTd",
        "outputId": "941385c3-763f-48b0-fab6-9803218411fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3173, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3888, in parseImpl\n",
            "    resultlist += exprtokens\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/results.py\", line 436, in __iadd__\n",
            "    otherdictitems = [\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/results.py\", line 437, in <listcomp>\n",
            "    (k, _ParseResultsWithOffset(v[0], addoffset(v[1])))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/results.py\", line 17, in __getitem__\n",
            "    def __getitem__(self, i):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 207, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 396, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 365, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 323, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud dataproc jobs submit pyspark --cluster=$CLUSTER --region=$REGION pyspark_project.py -- gs://$BUCKET/steam.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgJ_PnXiFZVn",
        "outputId": "859a8ea1-64e7-4efc-d2fc-c2f8762e7432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job [4e884a235b934390bb8388bb97a55671] submitted.\n",
            "Waiting for job output...\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/4e884a235b934390bb8388bb97a55671/pyspark_project.py\", line 8, in <module>\n",
            "    import nltk\n",
            "ModuleNotFoundError: No module named 'nltk'\n",
            "\n",
            "\n",
            "Command killed by keyboard interrupt\n",
            "\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud dataproc jobs submit pyspark --cluster=$CLUSTER --region=$REGION --py-files gs://$BUCKET/nltk.zip pyspark_project.py -- gs://$BUCKET/steam.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQNCTcxYuPGl",
        "outputId": "b5cf2447-5c16-43d7-8847-03f3b2998972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job [16cc74d715414c25b1f5c2ba3f41c0a8] submitted.\n",
            "Waiting for job output...\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/16cc74d715414c25b1f5c2ba3f41c0a8/pyspark_project.py\", line 9, in <module>\n",
            "    nltk.download('stopwords')\n",
            "AttributeError: module 'nltk' has no attribute 'download'\n",
            "\n",
            "\n",
            "Command killed by keyboard interrupt\n",
            "\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zao_GwHoLjIt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}